---
time_modified: 2024-10-03T23:28:28-04:00
time_created: 2024-09-25T20:58:02-04:00
---

- [ ] [Long-Context LLM Extension - YouTube](https://www.youtube.com/watch?v=dc4chADushM)
- [ ] [Everything About Long Context Fine-tuning](https://huggingface.co/blog/wenbopan/long-context-fine-tuning)

## RoPE Expansion

- [ ] [Gradient Blog: Scaling Rotational Embeddings for Long-Context Language Models](https://gradient.ai/blog/scaling-rotational-embeddings-for-long-context-language-models)
	- [ ] rope theta scaling + fine tuning on longer context data
- [ ] [Extending the RoPE | EleutherAI Blog](https://blog.eleuther.ai/yarn/)


## Sliding Window Attention



## Ring Attention

- [ ]  [RING Attention explained: 1 Mio Context Length - YouTube](https://www.youtube.com/watch?v=jTJcP8iyoOM)



## StreamingLLM

- [ ] [\[2309.17453\] Efficient Streaming Language Models with Attention Sinks](https://arxiv.org/abs/2309.17453)
	- [ ] [GitHub - mit-han-lab/streaming-llm: \[ICLR 2024\] Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)
- [ ] [StreamingLLM - Efficient Streaming Language Models with Attention Sinks Explained - YouTube](https://www.youtube.com/watch?v=f23sUViqxH8)

![[Pasted image 20241003221622.png]]

![[Pasted image 20241003221906.png]]