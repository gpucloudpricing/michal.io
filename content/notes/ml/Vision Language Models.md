---
time_modified: 2024-10-16T14:35:06-04:00
time_created: 2024-10-09T11:51:41-04:00
---

#vlm #multimodal 

- [ ] [\[2410.04751\] Intriguing Properties of Large Language and Vision Models](https://arxiv.org/abs/2410.04751)


# Models / Architectures

## Flamingo
- [ ] [\[2204.14198\] Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)

## Chameleon
- [ ] [\[2405.09818\] Chameleon: Mixed-Modal Early-Fusion Foundation Models](https://arxiv.org/abs/2405.09818)


## LLaVA


## Molmo


## Pixtral


## Qwen2 VL


## Aria
[\[2410.05993\] Aria: An Open Multimodal Native Mixture-of-Experts Model](https://arxiv.org/abs/2410.05993)

## Nvidia Eagle
[GitHub - NVlabs/EAGLE: EAGLE: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://github.com/NVlabs/EAGLE)


## NVLM


## Llama 3 Multimodal



# Design Space


## Early vs Late Fusion


## Positional Encoding


## Aspect Ratios and Input Sizes


## Modality Alignment


# Training

## Pretraining

## Adapter Alignment


## Full Fine Tuning vs Frozen


## Post Training / Instruction Tuning


# Benchmarks / Evals

- [ ] [MEGA-Bench](https://tiger-ai-lab.github.io/MEGA-Bench/)