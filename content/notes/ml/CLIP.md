---
time_modified: 2024-10-03T13:36:22-04:00
time_created: 2024-10-03T10:44:29-04:00
---

#clip #vision-language #contrastive #multimodal 



## Intro



## Speeding Up

### SigLip


### Distillation

- [ ] [\[2310.13355\] SILC: Improving Vision Language Pretraining with Self-Distillation](https://arxiv.org/abs/2310.13355)
	- [ ] [GitHub - google-research/silc: \[ECCV 2024\] Official Release of SILC: Improving vision language pretraining with self-distillation](https://github.com/google-research/silc)


## Uses of CLIP


### Classification

- [ ] [ECCV Poster uCAP: An Unsupervised Prompting Method for Vision-Language Models](https://eccv.ecva.net/virtual/2024/poster/2005#:~:text=These%20prompts%20are%20typically%20manually,only%20unlabeled%20in%2Ddomain%20images.)


## Data Curation

- [ ] [DataComp](https://www.datacomp.ai/dcclip/index.html#home)
- [ ] [DataComp Workshop](https://www.datacomp.ai/dcclip/workshop.html#first)

### Filtering

#### Deduplication

#### Noise

#### Quality Filtering
- [ ] Use pretrained CLIP model to filter out pairs with low score

### Augmentation