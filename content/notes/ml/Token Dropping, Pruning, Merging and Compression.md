
- [ ] [[KV Cache Compression]]
- [ ] [\[2412.00965v1\] Token Cropr: Faster ViTs for Quite a Few Tasks](https://arxiv.org/abs/2412.00965v1)

![[Screenshot 2024-12-03 at 11.32.35 AM.png]]![[Screenshot 2024-12-03 at 11.32.52 AM.png]]![[Screenshot 2024-12-03 at 11.33.00 AM.png]]



## Vision Language Models

- [ ] [\[2412.01818\] \[CLS\] Attention is All You Need for Training-Free Visual Token Pruning: Make VLM Inference Faster](https://arxiv.org/abs/2412.01818)
- [ ] [\[2411.03312v1\] Inference Optimal VLMs Need Only One Visual Token but Larger Models](https://arxiv.org/abs/2411.03312v1)
- [ ] [\[2412.06263\] iLLaVA: An Image is Worth Fewer Than 1/3 Input Tokens in Large Multimodal Models](https://arxiv.org/abs/2412.06263)