---
time_modified: 2024-11-04T06:38:43-05:00
time_created: 2024-09-10T07:26:54-04:00
---

## Models
- [ ] 
## Papers
- [ ] [\[2410.23262\] EMMA: End-to-End Multimodal Model for Autonomous Driving](https://arxiv.org/abs/2410.23262)
- [ ] [\[2411.03313\] Classification Done Right for Vision-Language Pre-Training](https://arxiv.org/abs/2411.03313)
- [ ] [\[2406.06484\] Parallelizing Linear Transformers with the Delta Rule over Sequence Length](https://arxiv.org/abs/2406.06484)
- [ ] [\[2411.02959\] HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems](https://arxiv.org/abs/2411.02959)
- [ ] [\[2411.04965\] BitNet a4.8: 4-bit Activations for 1-bit LLMs](https://arxiv.org/abs/2411.04965)
- [ ] [\[2411.04996\] Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models](https://arxiv.org/abs/2411.04996)
- [ ] [\[2411.04905\] OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models](https://arxiv.org/abs/2411.04905)
- [ ] [\[2410.17897\] Value Residual Learning For Alleviating Attention Concentration In Transformers](https://arxiv.org/abs/2410.17897)
- [ ] [\[2410.21228\] LoRA vs Full Fine-tuning: An Illusion of Equivalence](https://arxiv.org/abs/2410.21228)
- [ ] [\[2407.10964\] No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations](https://arxiv.org/abs/2407.10964)
- [ ] [\[2405.17604\] LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters](https://arxiv.org/abs/2405.17604)
- [ ] [\[2411.02853\] ADOPT: Modified Adam Can Converge with Any $Î²\_2$ with the Optimal Rate](https://arxiv.org/abs/2411.02853)

## Code
- [ ] [GitHub - run-ai/runai-model-streamer](https://github.com/run-ai/runai-model-streamer)

## Articles
- [ ] 

## Videos
- [ ] [YouTube](https://youtu.be/j-UeyJrlOEU?si=iQV-AWoQSYIEKePn)
- [ ] [Stanford Graph Learning Workshop 2024 - YouTube](https://www.youtube.com/live/gnTqU30rwaI)
- [ ] https://www.youtube.com/watch?v=0Yi3yUjB-3M&list=PPSV

## Other
- [ ]


## Tweets

![](https://x.com/_clashluke/status/1853587725636493503)


![](https://x.com/sytelus/status/1854085397124718892)


![](https://x.com/dome_271/status/1855298287810785397)


![](https://x.com/kellerjordan0/status/1855284499682333125)