
## Papers


### LLM distillation
- [ ] [\[2408.11796\] LLM Pruning and Distillation in Practice: The Minitron Approach](https://arxiv.org/abs/2408.11796)
	- [ ] [> Possibly everything-you-need to know about pruning and distillation of generative models](https://x.com/srchvrs/status/1828809715951759814)
- [ ] to SSMs
	- [ ] [\[2408.15237\] The Mamba in the Llama: Distilling and Accelerating Hybrid Models](https://arxiv.org/abs/2408.15237)

- [ ] [\[2408.15664\] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts](https://arxiv.org/abs/2408.15664)

### Multi Modal Models
- [ ] [\[2408.15998\] Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://arxiv.org/abs/2408.15998) #vlm
	- [ ] [GitHub - NVlabs/EAGLE: EAGLE: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://github.com/NVlabs/Eagle)
	- [ ] ![[Pasted image 20240829131300.png]]
- [ ] [LLaVA-OneVision: Easy Visual Task Transfer](https://llava-vl.github.io/blog/2024-08-05-llava-onevision/)
	- [ ] [LLaVA-OneVision: Easy Visual Task Transfer](https://llava-vl.github.io/blog/2024-08-05-llava-onevision/)
- [ ] [Qwen2-VL: To See the World More Clearly | Qwen](https://qwenlm.github.io/blog/qwen2-vl/)
	- [ ] [GitHub - QwenLM/Qwen2-VL: Qwen2-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.](https://github.com/QwenLM/Qwen2-VL)
	- [ ] [Binyuan Hui on X: "Try our new Qwen2-VL: https://t.co/uyIeCOtRUa ⚠️ Three Secrets of Success for Qwen2-VL ⚠️ 1️⃣ A key architectural improvement in Qwen2-VL is the implementation of Naive Dynamic Resolution support. Unlike its predecessor, Qwen2-VL can handle arbitrary image resolutions, mapping https://t.co/QtokQgJcqT" / X](https://x.com/huybery/status/1829187788153204776)
- [ ] [\[2408.16500\] CogVLM2: Visual Language Models for Image and Video Understanding](https://arxiv.org/abs/2408.16500)



## Code
- [ ] [GitHub - mixedbread-ai/batched](https://github.com/mixedbread-ai/batched)


## Datasets
- [ ] [Nous Research on X: "Introducing a new open dataset release, Hermes Function Calling V1, the datamix that gave Hermes 2 Pro its tool use and structured output capabilities. HuggingFace Repo: https://t.co/BEYzJzbesq The dataset includes single and multiturn Function Calling and Structured JSON https://t.co/ag4S1n1wwr" / X](https://x.com/NousResearch/status/1829143753036366325)

## Articles
- [ ] [Evaluating the Effectiveness of LLM-Evaluators (aka LLM-as-Judge)](https://eugeneyan.com/writing/llm-evaluators/)
- [ ] [LLM Evaluation doesn't need to be complicated](https://www.philschmid.de/llm-evaluation)


## Videos
- [ ] [Neural and Non-Neural AI, Reasoning, Transformers, and LSTMs - YouTube](https://www.youtube.com/watch?v=DP454c1K_vQ)
- [ ] [The Mamba in the Llama: Distilling and Accelerating Hybrid Models - YouTube](https://www.youtube.com/watch?v=A5ff8hu1amM)
- [ ] [Stanford CS229 I Machine Learning I Building Large Language Models (LLMs) - YouTube](https://www.youtube.com/watch?v=9vM4p9NN0Ts)
- [ ] [Arvind Narayanan: AI Scaling Myths, The Core Bottlenecks in AI Today & The Future of Models | E1195 - YouTube](https://www.youtube.com/watch?v=8CvjVAyB4O4)
- [ ] [Anthropic CEO Dario Amodei on AI's Moat, Risk, and SB 1047 - YouTube](https://www.youtube.com/watch?v=7xij6SoCClI)


## Tweets
- [ ] 