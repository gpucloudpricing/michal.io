---
time_modified: 2024-11-04T06:38:18-05:00
time_created: 2024-09-10T07:26:54-04:00
---

## Models
- [ ] [ColFlor: Towards BERT-Size Vision-Language Document Retrieval Models](https://huggingface.co/blog/ahmed-masry/colflor)
## Papers
- [ ] [\[2410.14072v1\] Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers](https://arxiv.org/abs/2410.14072v1)
- [ ] [\[2410.11190\] Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities](https://arxiv.org/abs/2410.11190)
- [ ] [\[2410.15458\] Allegro: Open the Black Box of Commercial-Level Video Generation Model](https://arxiv.org/abs/2410.15458)
- [ ] [\[2406.15786\] What Matters in Transformers? Not All Attention is Needed](https://arxiv.org/abs/2406.15786)
- [ ] [\[2410.15732v1\] ViMoE: An Empirical Study of Designing Vision Mixture-of-Experts](https://arxiv.org/abs/2410.15732v1)
	- [ ] fork pretrained ViT (DINOv2) by replicating FFN weights into multiple experts
	- [ ] route on CLS token to same experts at image level
	- [ ] load balancing loss for balanced routing
	- [ ] shared experts that are always active for "common knowledge"
	- [ ] top-1 expert routing
	- [ ] $$y = E_s(x) + \sum_{i \in \mathcal{T}} g_i(x_{\text{[CLS]}}) \cdot E_i(x)$$
		- [ ] Es = shared expert
- [ ] [\[2410.16261v1\] Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance](https://arxiv.org/abs/2410.16261v1)
- [ ] [https://openreview.net/pdf?id=vI95kcLAoU](https://openreview.net/pdf?id=vI95kcLAoU)
- [ ] [\[2410.16512v1\] TIPS: Text-Image Pretraining with Spatial Awareness](https://arxiv.org/abs/2410.16512v1)
- [ ] [\[2410.17243v1\] Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss](https://arxiv.org/abs/2410.17243v1)
- [ ] [\[2410.17251v1\] Altogether: Image Captioning via Re-aligning Alt-text](https://arxiv.org/abs/2410.17251v1)
- [ ] [\[2410.18967\] Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms](https://arxiv.org/abs/2410.18967)
## Code
- [ ] 

## Articles
- [ ] [Reaching 1B context length with RAG](https://www.zyphra.com/post/reaching-1b-context-length-with-rag)
- [ ] [How Speculative Decoding Boosts vLLM Performance by up to 2.8x | vLLM Blog](https://blog.vllm.ai/2024/10/17/spec-decode.html)
- [ ] [Simplifying, stabilizing, and scaling continuous-time consistency models | OpenAI](https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/)
- [ ] [Building Vectorize, a distributed vector database, on Cloudflareâ€™s Developer Platform](https://blog.cloudflare.com/building-vectorize-a-distributed-vector-database-on-cloudflare-developer-platform/)

## Videos
- [ ] 

## Other
- [ ]

**
## Tweets
