---
time_modified: 2024-10-11T23:02:03-04:00
time_created: 2024-09-10T07:26:54-04:00
---

## Models
- [ ] [nvidia/Hymba-1.5B-Base · Hugging Face](https://huggingface.co/nvidia/Hymba-1.5B-Base)
- [ ] [Cosmos Tokenizer: A suite of image and video neural tokenizers](https://research.nvidia.com/labs/dir/cosmos-tokenizer/) #star
	- [ ] [GitHub - NVIDIA/Cosmos-Tokenizer: A suite of image and video neural tokenizers](https://github.com/NVIDIA/Cosmos-Tokenizer)
- [ ] [Nexusflow/Athene-V2-Agent · Hugging Face](https://huggingface.co/Nexusflow/Athene-V2-Agent)
## Papers
- [ ] [\[2411.07975\] JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2411.07975)
- [ ] [\[2410.08020\] Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs](https://arxiv.org/abs/2410.08020)
- [ ] [\[2411.10440\] LLaVA-o1: Let Vision Language Models Reason Step-by-Step](https://arxiv.org/abs/2411.10440)
- [ ] [\[2411.10433\] M-VAR: Decoupled Scale-wise Autoregressive Modeling for High-Quality Image Generation](https://arxiv.org/abs/2411.10433)
- [ ] [\[2411.13676\] Hymba: A Hybrid-head Architecture for Small Language Models](https://arxiv.org/abs/2411.13676)
- [ ] [\[2411.14402\] Multimodal Autoregressive Pre-training of Large Vision Encoders](https://arxiv.org/abs/2411.14402) #star
- [ ] [\[2411.14347\] DINO-X: A Unified Vision Model for Open-World Object Detection and Understanding](https://arxiv.org/abs/2411.14347) #star
- [ ] [\[2411.12155\] Reinforcement Learning with Action Sequence for Data-Efficient Robot Learning](https://arxiv.org/abs/2411.12155)
- [ ] [\[2411.14429\] Revisiting the Integration of Convolution and Attention for Vision Backbone](https://arxiv.org/abs/2411.14429)

## Code
- [ ] [GitHub - apple/ml-aim: This repository provides the code and model checkpoints for AIMv1 and AIMv2 research projects.](https://github.com/apple/ml-aim)
- [ ] [GitHub - Lightricks/LTX-Video: Official repository for LTX-Video](https://github.com/Lightricks/LTX-Video)
- [ ] [GitHub - rayleizhu/GLMix: \[NeurIPS 2024\] official code release for our paper "Revisiting the Integration of Convolution and Attention for Vision Backbone".](https://github.com/rayleizhu/GLMix)

## Articles
- [ ] [You could have designed state of the art positional encoding](https://fleetwood.dev/posts/you-could-have-designed-SOTA-positional-encoding)
- [ ] [Extending the Context Length to 1M Tokens! | Qwen](https://qwenlm.github.io/blog/qwen2.5-turbo/)
## Videos
- [ ] [Tim Dettmers on Open-source AI, LMs, SWE Bench, Agents, Quantization, & Optimization - YouTube](https://youtu.be/0SVmBrbx2Rw?si=dYN7QX6LePbDrrtc)
- [ ] [Speculations on Test-Time Scaling (o1) - YouTube](https://youtu.be/6PEJ96k1kiw?si=SwGRFHON7Ic94OwF)
	- [ ] [Speculations on Test-Time Scaling | Richard M. Karp Distinguished Lecture - YouTube](https://www.youtube.com/live/6fJjojpwv1I?si=3vhIK8auuIKqiGLQ)
- [ ] [Retrieval augmented generation; Extractive summarization - YouTube](https://www.youtube.com/watch?v=Yxd-9NLifcg)
- [ ] [Learning at test time in LLMs - YouTube](https://www.youtube.com/watch?v=vei7uf9wOxI)
- [ ] [QA: Retrieval & Answer extraction - YouTube](https://www.youtube.com/watch?v=fxHDcqL0Qkg)
- [ ] [Flash Attention derived and coded from first principles with Triton (Python) - YouTube](https://www.youtube.com/watch?v=zy8ChVd_oTM&t=546s)
- [ ] [Guest Lecture 1: Or Patashnik - The Power of Attention Layers (KAIST CS492D, Fall 2024) - YouTube](https://www.youtube.com/watch?v=jkJ527y9PxI)

## Other
- [ ] [CS 886: Recent Advances on Foundation Models](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/)
- [ ] [Stanford Graph Learning Workshop 2024 | Stanford Engineering Data Science Applications](https://dsa.stanford.edu/events/conference/stanford-graph-learning-workshop-2024)


## Tweets

![](https://x.com/MustafaShukor1/status/1859896571984482630)


![](https://x.com/david_picard/status/1860412071424184772):