
## Models
- [ ] [Llama 3.2: Revolutionizing edge AI and vision with open, customizable models](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) #vlm
- [ ] [molmo.allenai.org/blog](https://molmo.allenai.org/blog)  molmo multimodal models #vlm
- [ ] [stepfun-ai/GOT-OCR2\_0 · Hugging Face](https://huggingface.co/stepfun-ai/GOT-OCR2_0) #ocr
- [ ] [GitHub - ByungKwanLee/Phantom: \[Under Review\] Official PyTorch implementation code for realizing the technical part of Phantom of Latent representing equipped with enlarged hidden dimension to build super frontier vision language models.](https://github.com/ByungKwanLee/Phantom) #vlm
## Papers
- [ ] [\[2409.13523\] EMMeTT: Efficient Multimodal Machine Translation Training](https://arxiv.org/abs/2409.13523)
- [ ] [\[2409.14683\] Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling](https://arxiv.org/abs/2409.14683)
- [ ] [\[2409.15278\] PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions](https://arxiv.org/abs/2409.15278)

## Code
- [ ] [RWKV-LM/RWKV-v7 at main · BlinkDL/RWKV-LM · GitHub](https://github.com/BlinkDL/RWKV-LM/tree/main/RWKV-v7)
- [ ] [GitHub - willccbb/mlx\_parallm: Fast parallel LLM inference for MLX](https://github.com/willccbb/mlx_parallm) #mlx #inference 

## Articles
- [ ] [The Practitioner's Guide to the Maximal Update Parameterization | EleutherAI Blog](https://blog.eleuther.ai/mutransfer/) #scaling
- [ ] [Understanding how LLM inference works with llama.cpp](https://www.omrimallis.com/posts/understanding-how-llm-inference-works-with-llama-cpp/) llama.cpp
- [ ] [Techniques for KV Cache Optimization in Large Language Models](https://www.omrimallis.com/posts/techniques-for-kv-cache-optimization/) #kvcache #llm #inference
- [ ] [The basic idea behind FlashAttention](https://peterchng.com/blog/2024/06/26/the-basic-idea-behind-flashattention/) #flash-attention #softmax
	- [ ] [From Online Softmax to FlashAttention](https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf)
- [ ] [FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention | PyTorch](https://pytorch.org/blog/flexattention/)
- [ ] [Tune Llama3 405B on AMD MI300x (our journey) - Felafax Blog - Obsidian Publish](https://publish.obsidian.md/felafax/pages/Tune+Llama3+405B+on+AMD+MI300x+(our+journey)) #amd #jax
- [ ] [Exploring Parallel Strategies with Jax | AstraBlog](https://astralord.github.io/posts/exploring-parallel-strategies-with-jax/) #distributed #jax
- [ ] [Power of Diffusion Models | AstraBlog](https://astralord.github.io/posts/power-of-diffusion-models/) #diffusion
- [ ] [GenAI Handbook](https://genai-handbook.github.io/)

## Videos
- [ ] [Boris Hanin | Scaling Limits of Neural Networks - YouTube](https://www.youtube.com/watch?v=0PJJ29jYIsg)
- [ ] [MLBBQ: Flash Atttention by Mike Doan - YouTube](https://www.youtube.com/watch?v=cJaPRbKcbl4&t=1283s) #flash-attention 

## Other
- [ ] 